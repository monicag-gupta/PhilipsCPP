Measuring Performance in VS2022
Visual Studio includes profiling tools:
Step-by-step:
Build in Release mode with full optimization.
Go to Debug → Performance Profiler.
Select:
CPU Usage (find slow functions)
Instrumentation (detailed function timings)
Concurrency Visualizer (for multithreaded apps)
Run your program & analyze hot paths.




Build in Release mode with full optimization

Switch the build configuration to Release
Look at the toolbar at the top (usually next to the green Run/Debug button).
You’ll see a dropdown with Debug selected by default.
Change it to Release.
This already tells VS2022 to disable debug checks and turn on optimizations by default.
You need to tell Visual Studio to use C++20 in both Debug and Release modes: project -> Properties -> (ensure Configuration = Release) -> Configuration Properties → C/C++ → Language -> C++ Language Standard -> ISO C++20 Standard (/std:c++20) -> OK -> Rebuild Project
Extra performance:
Under C/C++ → Code Generation → Enable Enhanced Instruction Set, pick AVX2 (or AVX-512 if your CPU supports it).


Right-click your project → Properties.
In the left tree:
Go to Configuration: Release (top dropdown in the Properties window).
Under Configuration Properties → C/C++ → Optimization:
Optimization → Maximize Speed (/O2)
Inline Function Expansion → Any Suitable (/Ob2)
Favor Size or Speed → Favor fast code (/Ot)
Omit Frame Pointers → Yes (/Oy)
Whole Program Optimization → Enable
Under Configuration Properties → Linker → Optimization:
Link Time Code Generation → Use Link Time Code Generation (/LTCG






Bottleneck analysis only makes sense if you’re profiling code as it will run in production.
Set Configuration → Release
Enable:
/O2 — Maximize Speed
/GL — Whole Program Optimization
/arch:AVX2 — Use modern CPU instructions (if supported)
/std:c++20 — Make sure modern features compile
Narrowing Down Bottlenecks Tips:
Use [Instrumentation] instead of Sampling if you need exact timing.
In C++20, also look for:
Unnecessary copies → fix with const&, string_view, span
Inefficient algorithms → switch to better STL algorithm or parallel STL (std::execution::par)
Branch misprediction → hint with [[likely]] / [[unlikely]]
Memory allocations → profile allocation count with Diagnostic Tools → Memory Usage
 




#include <iostream>
#include <fstream>
#include <chrono>
#include <thread>
#include <filesystem>

void slowFunction() {
    std::string result;
    for (int i = 0; i < 20000; ++i) {
        result += "data";
    }
}

void mediumFunction() {
    std::string result;
    result.reserve(20000 * 4);
    for (int i = 0; i < 20000; ++i) {
        result += "data";
    }
}

void fastFunction() {
    std::this_thread::sleep_for(std::chrono::milliseconds(10));
}

int main() {
    // Print working directory so you know where the file is saved
    std::cout << "Working directory: " << std::filesystem::current_path() << "\n";

    std::ofstream log("profile_output.txt");

    log << "Running demo with Instrumentation profiling...\n";

    auto start = std::chrono::high_resolution_clock::now();

    slowFunction();
    mediumFunction();
    fastFunction();

    auto end = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);

    log << "Total time: " << duration.count() << " ms\n";
    log.close();

    return 0;
}





Problem code:
#include <iostream>
#include <string>
#include <vector>

// Function takes std::string by value (copy!)
std::string repeatString(std::string s, int times) {
    std::string result;
    for (int i = 0; i < times; ++i) {
        result += s;
    }
    return result;
}

// Function takes vector<int> by value (copy!)
int sumVector(std::vector<int> v) {
    int sum = 0;
    for (auto i : v) {
        sum += i;
    }
    return sum;
}

int main() {
    std::string largeString(10000, 'x');
    std::vector<int> largeVector(100000, 1);

    auto start = std::chrono::high_resolution_clock::now();
    auto repeated = repeatString(largeString, 10);
    auto sum = sumVector(largeVector);
    auto end = std::chrono::high_resolution_clock::now();

    std::cout << "Repeat string length: " << repeated.length() << "\n";
    std::cout << "Sum vector: " << sum << "\n";

    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
    std::cout << "Duration (ms): " << duration.count() << "\n";

    return 0;
}





#include <iostream>
#include <string>
#include <string_view>
#include <vector>
#include <span>
#include <chrono>

// Using string_view and span to avoid copies
std::string repeatString(std::string_view s, int times) {
    std::string result;
    for (int i = 0; i < times; ++i) {
        result += s;
    }
    return result;
}

int sumVector(std::span<const int> v) {
    int sum = 0;
    for (auto i : v) {
        sum += i;
    }
    return sum;
}

int main() {
    std::string largeString(10000, 'x');
    std::vector<int> largeVector(100000, 1);

    auto start = std::chrono::high_resolution_clock::now();
    auto repeated = repeatString(largeString, 10);
    auto sum = sumVector(largeVector);
    auto end = std::chrono::high_resolution_clock::now();

    std::cout << "Repeat string length: " << repeated.length() << "\n";
    std::cout << "Sum vector: " << sum << "\n";

    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
    std::cout << "Duration (ms): " << duration.count() << "\n";

    return 0;
}



const std::string& and const std::vector<int>& avoid copies on function calls.
std::string_view is a lightweight, non-owning view of a string (no copy).Perfect for read-only access to strings or substrings.
std::span allows a view over any contiguous sequence (array, vector, etc.) without copying.





Inefficient algorithms:

#include <iostream>
#include <vector>
#include <chrono>

int sumEvenNumbers(const std::vector<int>& v) {
    int sum = 0;
    for (int x : v) {
        if (x % 2 == 0) {
            sum += x;
        }
    }
    return sum;
}

int main() {
    std::vector<int> data(10000000);
    for (int i = 0; i < 10000000; ++i) {
        data[i] = i;
    }

    auto start = std::chrono::high_resolution_clock::now();

    int total = sumEvenNumbers(data);

    auto end = std::chrono::high_resolution_clock::now();

    std::cout << "Sum of even numbers: " << total << "\n";

    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
    std::cout << "Time taken: " << duration.count() << " ms\n";

    return 0;
}





#include <iostream>
#include <vector>
#include <numeric>
#include <execution>
#include <chrono>

int sumEvenNumbersManual(const std::vector<int>& v) {
    int sum = 0;
    for (int x : v) {
        if (x % 2 == 0) sum += x;
    }
    return sum;
}

int sumEvenNumbersParallel(const std::vector<int>& v) {
    return std::transform_reduce(
        std::execution::par,
        v.begin(), v.end(),
        0,
        std::plus<>(),
        [](int x) { return (x % 2 == 0) ? x : 0; }
    );
}

int main() {
    std::vector<int> data(100000000);
    for (int i = 0; i < data.size(); ++i) {
        data[i] = i;
    }

    auto start = std::chrono::high_resolution_clock::now();
    int manualSum = sumEvenNumbersManual(data);
    auto end = std::chrono::high_resolution_clock::now();
    std::cout << "Manual sum: " << manualSum << "\n";
    std::cout << "Manual duration (ms): "
        << std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count() << "\n";

    start = std::chrono::high_resolution_clock::now();
    int parallelSum = sumEvenNumbersParallel(data);
    end = std::chrono::high_resolution_clock::now();
    std::cout << "Parallel sum: " << parallelSum << "\n";
    std::cout << "Parallel duration (ms): "
        << std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count() << "\n";

    return 0;
}




Fix 1: Use better STL algorithm (std::accumulate + std::copy_if or std::ranges in C++20)
This uses ranges views to filter evens lazily, then accumulate sum.
Cleaner and often more optimized by the compiler.
 
Fix 2: Use Parallel STL (std::execution::par) for speed
std::transform_reduce applies a transform ([](int x){...}) and reduces (sum) in parallel.
Takes advantage of multiple CPU cores.
Requires /std:c++17 or higher and Windows SDK that supports parallel STL.





Value vs reference semantics

Value Semantics
What it means:
When you copy a variable (or pass it to a function), a new independent copy of the data is created.
Changes to the copy do not affect the original.
Analogy:
You photocopy a document. Editing your copy does not change the original document.
In C++:
Built-in types (int, double, etc.) and user-defined types without explicit pointer sharing (unless explicitly designed otherwise) follow value semantics.
 Reference Semantics
What it means:
You are referring to the same object. 
No copy is made. Changes via the reference affect the original.
Analogy:
You give someone your only copy of a document. They can scribble on it, and you’ll see the changes.
In C++:
Achieved using references (T&) or pointers (T*).



#include <iostream>
#include <vector>
#include <chrono>

// Value semantics: Pass by value (copies the vector)
int sumEvenNumbersValue(std::vector<int> v) {
    int sum = 0;
    for (int x : v) {
        if (x % 2 == 0) {
            sum += x;
        }
    }
    return sum;
}

// Reference semantics: Pass by const reference (no copy)
int sumEvenNumbersRef(const std::vector<int>& v) {
    int sum = 0;
    for (int x : v) {
        if (x % 2 == 0) {
            sum += x;
        }
    }
    return sum;
}

int main() {
    const int SIZE = 10'000'000;
    std::vector<int> data(SIZE);
    for (int i = 0; i < SIZE; ++i) {
        data[i] = i;
    }

    // Value semantics timing
    auto startValue = std::chrono::high_resolution_clock::now();
    int totalValue = sumEvenNumbersValue(data);
    auto endValue = std::chrono::high_resolution_clock::now();
    std::chrono::duration<double> elapsedValue = endValue - startValue;

    // Reference semantics timing
    auto startRef = std::chrono::high_resolution_clock::now();
    int totalRef = sumEvenNumbersRef(data);
    auto endRef = std::chrono::high_resolution_clock::now();
    std::chrono::duration<double> elapsedRef = endRef - startRef;

    // Results
    std::cout << "Value semantics - Sum: " << totalValue 
              << ", Time: " << elapsedValue.count() << " seconds\n";
    std::cout << "Reference semantics - Sum: " << totalRef 
              << ", Time: " << elapsedRef.count() << " seconds\n";

    return 0;
}




How it works:
Value semantics (sumEvenNumbersValue) → takes std::vector<int> by value, which copies all 10M integers before summing.
Reference semantics (sumEvenNumbersRef) → takes const std::vector<int>&, no copy, directly processes the original.
Uses std::chrono to measure elapsed time for each case.
 
If you run this with 10 million elements:
Value semantics will be much slower because of the copy (hundreds of ms to seconds).
Reference semantics will be significantly faster since no copy is made.





#include <iostream>
#include <vector>
#include <chrono>

class BigObject {
public:
    std::vector<int> data;

    BigObject(size_t n) : data(n, 42) {
        std::cout << "Constructor\n";
    }

    // Copy constructor
    BigObject(const BigObject& other) : data(other.data) {
        std::cout << "Copy Constructor\n";
    }

    // Move constructor
    BigObject(BigObject&& other) noexcept : data(std::move(other.data)) {
        std::cout << "Move Constructor\n";
    }
};

// Case 1: Without copy elision (return by value without optimizations)
BigObject createWithoutElision(size_t n) {
    BigObject obj(n);
    return obj; // may cause copy if elision not applied
}

// Case 2: With copy elision (NRVO - Named Return Value Optimization)
BigObject createWithElision(size_t n) {
    return BigObject(n); // temporary directly constructed in caller
}

// Case 3: Using std::move to force move semantics
BigObject createWithMove(size_t n) {
    BigObject obj(n);
    return std::move(obj); // forces move
}

// Helper to time execution
template <typename Func>
void measureTime(const std::string& label, Func f) {
    auto start = std::chrono::high_resolution_clock::now();
    f();
    auto end = std::chrono::high_resolution_clock::now();
    std::chrono::duration<double> elapsed = end - start;
    std::cout << label << " took " << elapsed.count() << " seconds.\n\n";
}

int main() {
    size_t size = 50'000'000; // big data for visible timings

    std::cout << "=== Without Copy Elision ===\n";
    measureTime("Without Elision", [&]() {
        BigObject obj = createWithoutElision(size);
        });

    std::cout << "=== With Copy Elision ===\n";
    measureTime("With Elision", [&]() {
        BigObject obj = createWithElision(size);
        });

    std::cout << "=== With Move Semantics ===\n";
    measureTime("With Move", [&]() {
        BigObject obj = createWithMove(size);
        });

    return 0;
}






Move Semantics in C++ is a performance optimization feature introduced in C++11 that allows resources from one object to be transferred (moved) to another object instead of being copied.
This is especially useful for expensive-to-copy resources such as:
Large strings
Vectors
File handles
Dynamic memory
 Why Move Semantics?
When you copy an object:
A new object is created with its own copy of the data.
This often involves allocating memory and duplicating contents — which is slow.
When you move an object:
    The destination takes ownership of the source’s resources.
    The source is left in a valid but empty state.
    No deep copy is performed — only pointer values are swapped.





#include <iostream>
#include <vector>
#include <chrono>

class BigData {
public:
    std::vector<int> data;

    BigData(size_t size) : data(size) {
        std::cout << "Constructor: Allocating " << size << " elements\n";
    }

    // Copy constructor
    BigData(const BigData& other) : data(other.data) {
        std::cout << "Copy Constructor: Deep copying\n";
    }
};

BigData createBigData() {
    BigData temp(1000000); // large allocation
    return temp; // Will cause copy in C++03
}

int main() {
    auto start = std::chrono::high_resolution_clock::now();
    BigData obj = createBigData();
    auto end = std::chrono::high_resolution_clock::now();
    std::cout << "Time taken: "
              << std::chrono::duration<double>(end - start).count()
              << " seconds\n";
}




#include <iostream>
#include <vector>
#include <chrono>

class BigData {
public:
    std::vector<int> data;

    BigData(size_t size) : data(size) {
        std::cout << "Constructor: Allocating " << size << " elements\n";
    }

    // Copy constructor
    BigData(const BigData& other) : data(other.data) {
        std::cout << "Copy Constructor: Deep copying\n";
    }

    // Move constructor
    BigData(BigData&& other) noexcept : data(std::move(other.data)) {
        std::cout << "Move Constructor: Moving resources\n";
    }
};

BigData createBigData() {
    BigData temp(1000000);
    return temp; // In C++11+, this will call move constructor (or be elided)
}

int main() {
    auto start = std::chrono::high_resolution_clock::now();
    BigData obj = createBigData();
    auto end = std::chrono::high_resolution_clock::now();
    std::cout << "Time taken: "
        << std::chrono::duration<double>(end - start).count()
        << " seconds\n";
}




Move constructor signature:
ClassName(ClassName&& other) noexcept;
Takes an rvalue reference (&&).
Transfers ownership instead of copying.
Use std::move() when you explicitly want to move:
BigData b2 = std::move(b1); // b1 becomes empty
Performance:
Copy: O(N) for N elements.
Move: O(1) pointer swap.
Copy elision:
Sometimes C++ skips both copy and move entirely — even faster.
Guaranteed in C++17 for return values.





// inline_demo.cpp
#include <iostream>
#include <chrono>

#if defined(_MSC_VER)
#define FORCE_INLINE __forceinline
#define NO_INLINE __declspec(noinline)
#else
#define FORCE_INLINE inline __attribute__((always_inline))
#define NO_INLINE __attribute__((noinline))
#endif

// A volatile guard to prevent the optimizer from doing heavy algebraic simplification
volatile int volatile_guard = 0x9e3779b9;
volatile long long global_sink = 0; // prevents the compiler from removing the loop

NO_INLINE int add_noinline(int a, int b) {
    int t = a + b;
    t ^= volatile_guard;   // volatile read prevents some global loop simplifications
    return t;
}

inline int add_inline(int a, int b) {
    int t = a + b;
    t ^= volatile_guard;
    return t;
}

FORCE_INLINE int add_forceinline(int a, int b) {
    int t = a + b;
    t ^= volatile_guard;
    return t;
}

// Benchmark helper (simple, minimal-measurement overhead)
template<typename Fn>
double benchmark(Fn f, int iterations) {
    global_sink = 0;
    auto start = std::chrono::high_resolution_clock::now();
    for (int i = 0; i < iterations; ++i) {
        global_sink += f(i, i + 1);
    }
    auto end = std::chrono::high_resolution_clock::now();
    std::chrono::duration<double> sec = end - start;
    return sec.count();
}

int main() {
    // Adjust iterations to taste (lower if your machine is slow)
    const int iterations = 50'000'000;

    std::cout << "Iterations: " << iterations << "\n";

    double t_noinline = benchmark(add_noinline, iterations);
    std::cout << "NO_INLINE time:      " << t_noinline << " s  "
        << "(" << (t_noinline * 1e9 / iterations) << " ns/call)\n";

    double t_inline = benchmark(add_inline, iterations);
    std::cout << "inline time:         " << t_inline << " s  "
        << "(" << (t_inline * 1e9 / iterations) << " ns/call)\n";

    double t_forceinline = benchmark(add_forceinline, iterations);
    std::cout << "FORCE_INLINE time:   " << t_forceinline << " s  "
        << "(" << (t_forceinline * 1e9 / iterations) << " ns/call)\n";

    // print sink so compiler can't remove the loop
    std::cout << "global_sink: " << global_sink << "\n";
    return 0;
}







Force / prevent per-function
NO_INLINE (the macro) uses __declspec(noinline) so add_noinline will not be inlined even if the compiler would normally inline it.
FORCE_INLINE uses __forceinline (MSVC) to strongly request inlining — compiler may still ignore in some cases but usually will inline in Release.
NO_INLINE is the slowest because each call incurs function-call overhead (stack/frame, jump/return).
inline reduces overhead and lets optimizer combine operations (faster).
FORCE_INLINE may be slightly faster than plain inline when the compiler would otherwise not inline; often similar when compiler already inlines.







Loop unrolling is a compiler optimization (or manual technique) where the loop body is duplicated multiple times to reduce the number of loop control operations (increment, comparison, jump), which can improve performance by:
Reducing branch instructions.
Increasing instruction-level parallelism.
Allowing better CPU pipeline utilization.
Why it’s faster
Loop control operations happen ¼ as often.
More work per loop iteration.
CPU can parallelize independent additions better.
Steps to Apply Loop Unrolling
Identify a performance-critical loop.
Check if iterations are independent (no dependencies between loop steps).
Decide unrolling factor (2x, 4x, 8x — too high may cause cache issues).
Modify the loop body to process multiple items per iteration.
Add a tail loop for remaining elements if the size is not divisible by the unrolling factor.
Benchmark before and after (as sometimes the compiler already optimizes it).





#include <iostream>
#include <vector>
#include <chrono>

void normalLoop(const std::vector<int>& data) {
    auto start = std::chrono::high_resolution_clock::now();
    long long sum = 0;
    for (size_t i = 0; i < data.size(); ++i) {
        sum += data[i];
    }
    auto end = std::chrono::high_resolution_clock::now();
    std::chrono::duration<double> diff = end - start;
    std::cout << "[Normal Loop] Sum = " << sum << ", Time = " << diff.count() << " s\n";
}

void unrolledLoop(const std::vector<int>& data) {
    auto start = std::chrono::high_resolution_clock::now();
    long long sum = 0;
    size_t i = 0;
    size_t limit = data.size() - (data.size() % 4);
    for (; i < limit; i += 4) {
        sum += data[i] + data[i + 1] + data[i + 2] + data[i + 3];
    }
    for (; i < data.size(); ++i) {
        sum += data[i];
    }
    auto end = std::chrono::high_resolution_clock::now();
    std::chrono::duration<double> diff = end - start;
    std::cout << "[Unrolled Loop 4x] Sum = " << sum << ", Time = " << diff.count() << " s\n";
}

int main() {
    const size_t N = 100'000'000;
    std::vector<int> data(N, 1);

    normalLoop(data);
    unrolledLoop(data);
}






Each loop iteration requires:
1.	Increment i
2.	Compare i to N
3.	Jump to loop start
4.	Load value and add
→ Millions of extra branch & comparison instructions.

Fix — With Loop Unrolling
We unroll the loop by processing 4 elements per iteration

Why it’s faster
•	Loop control operations happen ¼ as often.
•	More work per loop iteration.
•	CPU can parallelize independent additions better.






Memory alignment means arranging data in memory so that its address is a multiple of its size (or a platform-specific alignment boundary).For example, on a 64-bit system:
int (4 bytes) is typically aligned at 4-byte boundaries.
double (8 bytes) is typically aligned at 8-byte boundaries.
When variables are not aligned properly:
The CPU may need multiple memory reads/writes to fetch/store the data.
This results in slower performance.
On some architectures, misalignment can cause crashes.
Steps to Fix Misalignment
Group larger types first (e.g., double, then int, then char).
Minimize padding by ordering members from largest to smallest type size.
If needed, use:
alignas() to explicitly align.
#pragma pack(push, 1) / #pragma pack(pop) for packed structs (be careful, can hurt performance if CPU doesn’t support unaligned access efficiently).
Verify with sizeof(structName) to see space usage.




#include <iostream>
#include <chrono>
#include <vector>

struct Misaligned {
    char a;
    double b;
    char c;
    int d;
};

struct Aligned {
    double b;
    int d;
    char a;
    char c;
};

template<typename T>
double testAccess(const std::string& name) {
    const size_t N = 10'000'000;
    std::vector<T> data(N);

    auto start = std::chrono::high_resolution_clock::now();
    volatile double sum = 0;
    for (size_t i = 0; i < N; ++i) {
        sum += data[i].b;
    }
    auto end = std::chrono::high_resolution_clock::now();

    double ms = std::chrono::duration<double, std::milli>(end - start).count();
    std::cout << name << " sum: " << sum << "\n";
    std::cout << name << " Time: " << ms << " ms, Size: " << sizeof(T) << " bytes\n";
    return ms;
}

int main() {
    double t1 = testAccess<Misaligned>("Misaligned");
    double t2 = testAccess<Aligned>("Aligned");

    std::cout << "Speedup: " << t1 / t2 << "x faster with alignment.\n";
}





Without Problem (Misaligned Struct)
Here, we’ll put members in a bad order so that the compiler inserts padding, wasting space and possibly hurting performance.
Problem:
Padding between members increases struct size.
Less data fits in CPU cache → slower iteration.
 
With Fix (Aligned Struct)
We reorder members so that larger types come first, minimizing padding.

Memory layout: CPUs generally require certain types to be stored at aligned addresses (e.g., double must start at an address divisible by 8 bytes for best performance).The compiler inserts padding bytes to meet these rules.






#include <iostream>
#include <vector>
#include <chrono>

constexpr int N = 2000;

int main() {
    std::vector<std::vector<int>> matrix(N, std::vector<int>(N, 1));
    long long sum = 0;
    auto start = std::chrono::high_resolution_clock::now();

    // BAD: Accessing column-wise (causes cache misses)
    for (int col = 0; col < N; ++col) {
        for (int row = 0; row < N; ++row) {
            sum += matrix[row][col];
        }
    }
    auto end = std::chrono::high_resolution_clock::now();
    std::chrono::duration<double> elapsed = end - start;
    std::cout << "Sum: " << sum << "\n";
    std::cout << "Time (Cache-Unfriendly): " << elapsed.count() << " sec\n";
}




#include <iostream>
#include <vector>
#include <chrono>

constexpr int N = 2000;

int main() {
    std::vector<std::vector<int>> matrix(N, std::vector<int>(N, 1));
    long long sum = 0;
    auto start = std::chrono::high_resolution_clock::now();

    // GOOD: Accessing row-wise (matches row-major storage)
    for (int row = 0; row < N; ++row) {
        for (int col = 0; col < N; ++col) {
            sum += matrix[row][col];
        }
    }
    auto end = std::chrono::high_resolution_clock::now();
    std::chrono::duration<double> elapsed = end - start;
    std::cout << "Sum: " << sum << "\n";
    std::cout << "Time (Cache-Friendly): " << elapsed.count() << " sec\n";
}







#include <iostream>
#include <vector>
#include <string>
#include <chrono>

// A simple big object to show cost of copying vs moving
class BigData {
public:
    std::vector<int> data;

    // Constructor: allocate large data
    BigData(size_t size) {
        data.resize(size, 42); // fill with dummy data
        std::cout << "Constructor: Allocated " << size << " integers.\n";
    }

    // Copy Constructor
    BigData(const BigData& other) {
        data = other.data;
        std::cout << "Copy Constructor called.\n";
    }

    // Move Constructor
    BigData(BigData&& other) noexcept {
        data = std::move(other.data);
        std::cout << "Move Constructor called.\n";
    }

    // Assignment operators
    BigData& operator=(const BigData& other) {
        data = other.data;
        std::cout << "Copy Assignment called.\n";
        return *this;
    }

    BigData& operator=(BigData&& other) noexcept {
        data = std::move(other.data);
        std::cout << "Move Assignment called.\n";
        return *this;
    }
};

// Function taking lvalue reference
void processLValue(BigData& obj) {
    std::cout << "Processing LValue (no move)\n";
}

// Function taking rvalue reference
void processRValue(BigData&& obj) {
    std::cout << "Processing RValue (can move)\n";
}

// Simulate a function returning BigData (rvalue)
BigData createBigData(size_t size) {
    return BigData(size);
}

int main() {
    using namespace std::chrono;

    std::cout << "=== Lvalue vs Rvalue Reference Example ===\n";

    // Create object
    BigData a(5'000'000); // large object
    processLValue(a);     // Pass lvalue
    processRValue(std::move(a)); // Force rvalue

    std::cout << "\n=== Copy vs Move Timing ===\n";

    BigData b(10'000'000); // Big data

    // Copy timing
    auto start_copy = high_resolution_clock::now();
    BigData copyB = b; // calls copy constructor
    auto end_copy = high_resolution_clock::now();

    auto copy_time = duration_cast<milliseconds>(end_copy - start_copy).count();

    // Move timing
    auto start_move = high_resolution_clock::now();
    BigData moveB = std::move(b); // calls move constructor
    auto end_move = high_resolution_clock::now();

    auto move_time = duration_cast<milliseconds>(end_move - start_move).count();

    std::cout << "\nCopy Time: " << copy_time << " ms\n";
    std::cout << "Move Time: " << move_time << " ms\n";

    std::cout << "\n=== Returning Rvalue from Function ===\n";
    BigData c = createBigData(5'000'000); // RVO or move

    return 0;
}





















